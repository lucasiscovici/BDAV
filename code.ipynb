{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.base  import BaseEstimator, TransformerMixin\n",
    "from  sklearn.pipeline  import Pipeline\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from  sklearn.multiclass import OneVsRestClassifier\n",
    "import os\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier,PositiveNaiveBayesClassifier\n",
    "import sys\n",
    "from nltk.classify import SklearnClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CLASS POUR CREER DES OBJECTS AVEC DES NOMS COMME ON VEUX\n",
    "# s= S(hello=\"helloWorld\",coucou=\"j'aime le poisson\")\n",
    "# s.hello ( \"helloWorld)\n",
    "# Change to dict \n",
    "# s.toDict()[\"hello\"] (\"helloWorld\")\n",
    "class S(object):\n",
    "    def __init__(self, **entries): self.__dict__.update(entries)    \n",
    "    def __str__(self):\n",
    "        sf=[]\n",
    "        for i,j in getParams(self).items():\n",
    "            sf.append(str(i)+\" \"+str(j))\n",
    "        return \"\\n\".join(sf)\n",
    "    def __repr__(self):\n",
    "        return S.__str__(self)\n",
    "    def __getitem__(self,e):\n",
    "        return vars(self)[e]\n",
    "    def toDict():\n",
    "        return vars(self)\n",
    "#USEFULL\n",
    "def createVarLocalePython(k,v): vars()[k]=v\n",
    "def createVarPython(k,v): globals()[k]=v\n",
    "class ColumnSelector(object):\n",
    "    \"\"\"\n",
    "    A feature selector for scikit-learn's Pipeline class that returns\n",
    "    specified columns from a numpy array.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.cols]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "class toHotCls(object):\n",
    "    \"\"\"\n",
    "    A feature selector for scikit-learn's Pipeline class that returns\n",
    "    specified columns from a numpy array.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, fn):\n",
    "        self.fn = fn\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        def toHot(arr,d):\n",
    "            m=d\n",
    "            k={\"FALSE\":-1}\n",
    "            kk=[]\n",
    "            for i,j in enumerate(m):\n",
    "                k[j]=i\n",
    "            for i in arr:\n",
    "                kk.append(k[i])\n",
    "            return np.array(kk,dtype=np.int)\n",
    "        return toHot(X,self.fn)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "class ToLabelYCls:\n",
    "    def __init__(self, fn, delete=False):\n",
    "        self.fn=fn\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        def GetTestY(d,fnc=fnc_basic):\n",
    "            a=d\n",
    "            aa=[]\n",
    "            for i in a:\n",
    "                s=False\n",
    "                for k,v in fnc_basic.iteritems():\n",
    "                    if v(i):\n",
    "                        s=True\n",
    "                        aa.append(k)\n",
    "                if not s and not delete:\n",
    "                    aa.append(\"PB\")\n",
    "            return aa\n",
    "        return GetTestY(X,self.fn)\n",
    "class RemoveIf:\n",
    "    def __init__(self, fn,col=None):\n",
    "        self.fn=fn\n",
    "        self.col=col\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        XX=self.col if self.col is not None  else \":\"\n",
    "        return X[X[self.col].apply(lambda a: not self.fn(a))] if self.col is not None  else X[X.apply(lambda a: not self.fn(a))]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PRE-TRAITEMENT\n",
    "import re, sys\n",
    "import HTMLParser\n",
    "from nltk.corpus import stopwords\n",
    "h = HTMLParser.HTMLParser()\n",
    "emoji_pattern = re.compile(\n",
    "    u\"(\\ud83d[\\ude00-\\ude4f])|\"  # emoticons\n",
    "    u\"(\\ud83d[\\u0000-\\uddff])|\"  # symbols & pictographs (2 of 2)\n",
    "    u\"(\\ud83d[\\ude80-\\udeff])|\"  # transport & map symbols\n",
    "    u\"(\\uD83E[\\uDD00-\\uDDFF])|\"\n",
    "    u\"(\\ud83c[\\udf00-\\uffff])|\"  # symbols & pictographs (1 of 2)\n",
    "    u\"(\\ud83c[\\udde0-\\uddff])|\"  # flags (iOS)\n",
    "    u\"([\\u2934\\u2935]\\uFE0F?)|\"\n",
    "    u\"([\\u3030\\u303D]\\uFE0F?)|\"\n",
    "    u\"([\\u3297\\u3299]\\uFE0F?)|\"\n",
    "    u\"([\\u203C\\u2049]\\uFE0F?)|\"\n",
    "    u\"([\\u00A9\\u00AE]\\uFE0F?)|\"\n",
    "    u\"([\\u2122\\u2139]\\uFE0F?)|\"\n",
    "    u\"(\\uD83C\\uDC04\\uFE0F?)|\"\n",
    "    u\"(\\uD83C\\uDCCF\\uFE0F?)|\"\n",
    "    u\"([\\u0023\\u002A\\u0030-\\u0039]\\uFE0F?\\u20E3)|\"\n",
    "    u\"(\\u24C2\\uFE0F?|[\\u2B05-\\u2B07\\u2B1B\\u2B1C\\u2B50\\u2B55]\\uFE0F?)|\"\n",
    "    u\"([\\u2600-\\u26FF]\\uFE0F?)|\"\n",
    "    u\"([\\u2700-\\u27BF]\\uFE0F?)\"\n",
    "    \"+\", flags=re.UNICODE) \n",
    "\n",
    "def remove_accent(s):\n",
    "    import unicodedata\n",
    "    s1 = unicode(s,'utf-8')\n",
    "    return unicodedata.normalize('NFD', s1).encode('ascii', 'ignore') \n",
    "\n",
    "def remove_emoji(text):\n",
    "    text = text.decode('utf8')\n",
    "    return emoji_pattern.sub(r'', text).encode('utf8')\n",
    "\n",
    "def removeBackslash(text):\n",
    "    sk=re.compile(\n",
    "    \"\\\\\\\\n|\\\\\\\\r\")\n",
    "    return sk.sub(r'',text)\n",
    "    \n",
    "def traitement(text):\n",
    "    return remove_accent(h.unescape(removeBackslash(remove_accent(remove_emoji(text))).lower()).encode(\"utf-8\"))\n",
    "\n",
    "def removeRegex(d,rec):\n",
    "    return re.sub(rec, '',d)\n",
    "\n",
    "def removeRegexList(d,arr):\n",
    "    for i in arr:\n",
    "        d=removeRegex(d,i)\n",
    "    return d\n",
    "def remoteMultiSpace(d):\n",
    "    return \" \".join(d.split())\n",
    "\n",
    "class PreTraitement:\n",
    "    @staticmethod\n",
    "    def transform( X,name):\n",
    "        return [remoteMultiSpace(traitement(removeRegex(str(i),r'(\\'\\s*\\')|[0-9]'))) for i in X[name]]\n",
    "s_wFr=stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TRAITEMENT TEXT NGRAM - LEMMA\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import time\n",
    "import treetaggerwrapper\n",
    "tokenizerG = RegexpTokenizer(r'[\\w\\']+')\n",
    "\n",
    "def getLemma(word):\n",
    "    global memory\n",
    "    s=time.time()\n",
    "    tagger = treetaggerwrapper.TreeTagger(TAGLANG='fr',TAGPARFILE=\"/Users/lucasiscovici/Downloads/lib/french-utf8.par\")\n",
    "    words2=[]\n",
    "    words3={}\n",
    "    for j,i in enumerate(word):\n",
    "        if i in memory:\n",
    "            words3[j]=memory[i]\n",
    "        else:\n",
    "            words2.append(i)\n",
    "    if len(words2)>0:\n",
    "        tags = tagger.tag_text(words2,tagonly=True)\n",
    "    else:\n",
    "        tags = []\n",
    "    listla=[i.lemma for i in treetaggerwrapper.make_tags(tags)]\n",
    "    listReturn =[]\n",
    "    count=0\n",
    "    for j,i in enumerate(word):\n",
    "        if j in words3:\n",
    "            listReturn.append(words3[j])\n",
    "        else:\n",
    "            listReturn.append(listla[count])\n",
    "            memory[i]=listla[count]\n",
    "            count+=1\n",
    "    s2=time.time()\n",
    "    return listReturn\n",
    "def find_ngrams(input_list, n):\n",
    "    return [\" \".join(i) for i in zip(*[input_list[i:] for i in range(n)])]\n",
    "def getBiGrams(inpute):\n",
    "    return find_ngrams(inpute,2)\n",
    "def getTriGrams(inpute):\n",
    "    return find_ngrams(inpute,3)\n",
    "def word_feats(words,tr=False):\n",
    "    return dict([(word, True) for word in words]) if tr else [word for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LOAD DATA AND PRE-TRAIREMENT\n",
    "def _loadData(delim=\"\\|\\|\\|\",resetIndex=True,DirData=\"dataTer/\",names=[\"comment\",\"rate\",\"rateM\"],debug=False):\n",
    "    #FCT TO READ_CSV FROM FILENAME \n",
    "    importCsvFromFileName = lambda file_name : pd.read_csv(file_name,delimiter=delim,names=names)\n",
    "    # Load AND Combine all Data Together\n",
    "    def mergeAllData(Dir):\n",
    "        data=pd.DataFrame()\n",
    "        rootdir = Dir\n",
    "        for subdir, dirs, files in os.walk(rootdir):\n",
    "            print(\"Load Data MergeAllData: Dir: %s\" % subdir)\n",
    "            for file in files:\n",
    "                data = data.append(importCsvFromFileName(os.path.join(subdir, file)))\n",
    "        return data\n",
    "    data = mergeAllData(DirData)\n",
    "    #IF ResetIndex is True, reset Index  of dataFrame, from 0 to len(data)\n",
    "    data = data.reset_index() if resetIndex else data\n",
    "    if debug:\n",
    "        print(\"Len Of Data: %s\" % data.count())\n",
    "    return data\n",
    "def loadData(Reload=False,default_name=\"reviews\",params_loadData=[]):\n",
    "    Sreturn = lambda data,code: S(data=data,code=code)\n",
    "    if os.path.isfile(default_name) and not Reload:\n",
    "        return Sreturn(pd.read_pickle(default_name),0)\n",
    "    return Sreturn(_loadData(*params_loadData),1)\n",
    "\n",
    "def loadDataAndPreTraiIf(default_name=\"reviews\",columnName=\"comment\",paramsLoadData=[]):\n",
    "    def applyPreTraitementTo(dest,source,column=columnName):\n",
    "        dest[column]=PreTraitement.transform(source,column)\n",
    "    #LOAD DATA - DEJA PRE-TRAITÉES\n",
    "    def saveReviewsPreTraited(d,name):   \n",
    "        d.to_pickle(name)\n",
    "    Sdata=loadData(*paramsLoadData)\n",
    "    reviews=data=Sdata.data\n",
    "    if Sdata.code==1:\n",
    "        applyPreTraitementTo(reviews,data,columnName)\n",
    "        saveReviewsPreTraited(reviews,default_name)\n",
    "    return reviews\n",
    "\n",
    "#LOAD MEMORY FOR TREE TAGER CALL\n",
    "def memoryFC():\n",
    "    memory=None\n",
    "    def loadMemory():\n",
    "        global memory\n",
    "        memory=np.load(\"memory\").tolist()\n",
    "\n",
    "    #SAVE\n",
    "    def saveMemory():\n",
    "        global memory\n",
    "        np.array(memory).dump(\"memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CopyData\n",
    "reviews=loadDataAndPreTraiIf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Pre-Traitement pour preparer les data pour le training format en dictionnaire\n",
    "#UNIGRAM -> lemminization\n",
    "#sentence to Word and Apply Funct Fn dessus\n",
    "def buildToWord(nltkFormat=True):\n",
    "    _fcDef= lambda j:j # FCP PAR DEFAUT (FAIT RIEN)\n",
    "    __toWord = lambda fn, i, jj=False : fn([unicode(j,'utf-8') for j in tokenizerG.tokenize(i) ],jj) #BASE POUR TOKENISER\n",
    "    _wf=lambda fn: lambda i,jj=False: word_feats(fn(i),jj) #BASE POUR FORMAT NLTK \n",
    "\n",
    "    _toWord = lambda fc: lambda i, jj=False : __toWord(_wf(fc),i,jj)\n",
    "    _toWordBis=lambda k: lambda n: words[k](n,nltkFormat)\n",
    "    baseWord=\"toWord\"\n",
    "    Words={\"WithoutLemma\":_fcDef,\"Uni\":getLemma,\"Bi\":getBiGrams,\"Tri\":getTriGrams}\n",
    "    words={}\n",
    "    wordsBi={}\n",
    "    for k,v in Words.iteritems():\n",
    "        #words+=[S(toWord=_toWord(v),name=baseWord+k)]\n",
    "        words[k]=_toWord(v)\n",
    "        wordsBi[k]=_toWordBis(k)\n",
    "    return (words,wordsBi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toWORDS=buildToWord()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#apply fct on data \n",
    "# For Filter\n",
    "# Per exemple {\"neg\":lambda d: d[d.rate < 3.]}\n",
    "\n",
    "#CREATE ARRAY WITH APLICATION OF len(FNS) FUNCTIONS ON DATA\n",
    "def prepareData(data,fns):\n",
    "    return [v(data) for k,v in fns.iteritems()]\n",
    "\n",
    "#BUILD CLASSIFIER \n",
    "# dataset\n",
    "# fc: function to apply for this classifer to build dataSet (create n-gram)\n",
    "# debug\n",
    "# sklearn : Not use nltk Naive Bayes, But the Naive Bayes of Sklearn (But with the help of nltk)\n",
    "# sklearn : NaiveBayes to Use pour Sklearn (BernoulliNB, GaussianNB, MultinomialNB)\n",
    "# fnc : How to prepareData ?  Which Data To Select ? Wich Label ? {\"neg\":lambda d: d[d.rate < 3.]}\n",
    "# testPart: Percentage of train Data\n",
    "# CollunsName To select for the dataset (comment)\n",
    "def iiOk(d,maxx):\n",
    "    print(d,maxx)\n",
    "    return [0]*(d)+[1]+[0]*(maxx-d-1)\n",
    "\n",
    "#\n",
    "def get_classifier(dataset=reviews2,fc=toWord,debug=False,sklearn=False,sklearnNB=BernoulliNB,\n",
    "                   fnc={},testPart=3/4.,colunmName=\"comment\",arrLabelFormat=False):\n",
    "        \n",
    "    arr=prepareData(dataset,fnc)#Prepare Data\n",
    "    print(\"Len: \"+str(len(dataset)))\n",
    "    #print(arr)\n",
    "    Data=[]\n",
    "    #For each Key in fnc (each Label , each Y)\n",
    "    for i,k in enumerate(fnc):\n",
    "        if debug:\n",
    "            print(k+\":\")\n",
    "            sys.stdout.flush()\n",
    "        data=arr[i][colunmName] #Get prepared Data # LES COMMENTAIRES\n",
    "        dataUp=[]\n",
    "        for ii,f in enumerate(data):  #Loop Data COMMENTS\n",
    "            if debug:\n",
    "                sys.stdout.write(str(ii/float(len(data)))+\"\\r\")\n",
    "                sys.stdout.flush()\n",
    "            dataUp.append((fc(f), [k] if arrLabelFormat else k) ) #Build n-gram with function fc\n",
    "        \n",
    "        Data.append(dataUp)\n",
    "        if debug:\n",
    "            sys.stdout.flush()\n",
    "            sys.stdout.write(\"\\r1     \\n\")\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    DataTrainTest=[]\n",
    "    for i in Data: #Know what size of each Label We Want \n",
    "        #print(len(i))\n",
    "        DataTrainTest.append(int(len(i)*testPart))\n",
    "    \n",
    "    #Build train ANd Test DataSet\n",
    "    trainfeats = []\n",
    "    testfeats  = []\n",
    "    for i,j in enumerate(Data):\n",
    "        #print(DataTrainTest[i])\n",
    "        trainfeats+=j[:DataTrainTest[i]]\n",
    "        testfeats+=j[DataTrainTest[i]:]\n",
    "    if debug:\n",
    "        print 'train on %d instances, test on %d instances' % (len(trainfeats), len(testfeats))\n",
    "        print(trainfeats)\n",
    "    \n",
    "    classifier = SklearnClassifier(sklearnNB()).train(trainfeats) if sklearn else NaiveBayesClassifier.train(trainfeats)\n",
    "    k=nltk.classify.util.accuracy(classifier, testfeats)\n",
    "    if debug:\n",
    "        print 'accuracy:', k\n",
    "        if not sklearn: classifier.show_most_informative_features()\n",
    "    return [[classifier,k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SI get_classifier for more explanation\n",
    "nbl=0 #Lower Bound\n",
    "nb=1000 # Upper Bound Test sur nb val\n",
    "debug=False\n",
    "Sklearn=True\n",
    "SklearnParamNB=MultinomialNB\n",
    "reviews2=reviews[nbl:nb]\n",
    "toWordsBis=toWORDS[1]\n",
    "testVar={\n",
    "    \"_1gram\":toWordsBis[\"Uni\"],\n",
    "    \"_2gram\":toWordsBis[\"Bi\"],\n",
    "    \"_3gram\":toWordsBis[\"Tri\"]\n",
    "} # POUR AJOUTER/SUPPR/MODIF DES CLASSIFIEURS c'est ICI\n",
    "\n",
    "fnc_basic={\n",
    "    \"neg\":lambda d: d < 3.,\n",
    "    \"pos\":lambda d: d > 3\n",
    "} # BASE FOR FIND LABELS,POUR ENLEVER OU AJOUTER DES LABELS C'esT ICI\n",
    "select= lambda d,e,f :d[d.rate.apply(lambda dd:f(dd))]\n",
    "fnc={k:(lambda v: lambda d:select(d,\"rate\",v))(v) for k,v in fnc_basic.items()} # BASE FOR FIND IN DATAFRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni=(1,1)\n",
    "bi=(2,2)\n",
    "tri=(3,3)\n",
    "XpipeParams={\"UNI\":uni,\"BI\":bi,\"TRI\":tri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 35 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "def getPipelinesX(arr,fit_transform=None):\n",
    "    def getPipelineX(ngram=(1,1),max_df=0.5,min_df=2,fit_transform=None):\n",
    "        \n",
    "        vect=('vect', CountVectorizer(ngram_range=ngram,max_df=max_df,min_df=min_df))\n",
    "        vecto=('vecto', CountVectorizer(ngram_range=ngram))\n",
    "        colS=(\"colSel\",ColumnSelector(\"comment\"))\n",
    "        normal=[colS,\n",
    "            vect,\n",
    "               ('clf', MultinomialNB()) ]\n",
    "        rmIf=(\"removeIf\",RemoveIf(lambda d: d == 3.,\"rate\"))\n",
    "        nnormal=normal\n",
    "        \n",
    "        ke=Pipeline(nnormal)\n",
    "        if fit_transform is not None:\n",
    "            ke.fit_transform(fit_transform)\n",
    "        \n",
    "        return [ke,Pipeline([rmIf])]\n",
    "    return {k:getPipelineX(ngram=v,min_df=3,max_df=.5) for k,v in arr.iteritems()}\n",
    "p=getPipelinesX(XpipeParams)\n",
    "\n",
    "#features_nd = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(p[\"UNI\"][-1].fit_transform(reviews2),labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\n",
    "def display_accuracy_score(y_test, y_pred_class):\n",
    "    score = accuracy_score(y_test, y_pred_class)\n",
    "    print 'accuracy score: %s' % '{:.2%}'.format(score)\n",
    "    return score\n",
    "\n",
    "def display_null_accuracy(y_test):\n",
    "    value_counts = pd.value_counts(y_test)\n",
    "    null_accuracy = max(value_counts) / float(len(y_test))\n",
    "    print 'null accuracy: %s' % '{:.2%}'.format(null_accuracy)\n",
    "    return null_accuracy\n",
    "\n",
    "def display_accuracy_difference(y_test, y_pred_class):\n",
    "    null_accuracy = display_null_accuracy(y_test)\n",
    "    accuracy_score = display_accuracy_score(y_test, y_pred_class)\n",
    "    difference = accuracy_score - null_accuracy\n",
    "    if difference > 0:\n",
    "        print 'model is %s more accurate than null accuracy' % '{:.2%}'.format(difference)\n",
    "    elif difference < 0:\n",
    "        print 'model is %s less accurate than null accuracy' % '{:.2%}'.format(abs(difference))\n",
    "    elif difference == 0:\n",
    "        print 'model is exactly as accurate as null accuracy'\n",
    "    return null_accuracy, accuracy_score\n",
    "\n",
    "def train_test_and_evaluate(pipeline, X_train, y_train, X_test, y_test):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred_class = pipeline.predict(X_test)\n",
    "    display_accuracy_difference(y_test, y_pred_class)\n",
    "    classification_reports = confusion_matrix(y_test, y_pred_class)\n",
    "    print '-' * 75 + '\\nConfusion Matrix\\n'\n",
    "    print classification_reports\n",
    "    print '-' * 75 + '\\nClassification Report\\n'\n",
    "    print classification_report(y_test, y_pred_class)\n",
    "      \n",
    "    return pipeline, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn_helpers import train_test_and_evaluate\n",
    "sentiment_pipeline, confusion_matrix = train_test_and_evaluate(LogisticRegression(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "xx=[]\n",
    "for k,v in p.iteritems():\n",
    "    xx+=[(k,v[0])]\n",
    "v=VotingClassifier(estimators=xx,voting=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_pipeline, confusion_matrix = train_test_and_evaluate(v.estimators_[1], X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(debut=1000,fin=100000,pas=1000,voting=\"soft\"):\n",
    "    global reviews,XpipeParams,fnc_basic\n",
    "    from matplotlib.legend_handler import HandlerLine2D\n",
    "    p2=Pipeline([\n",
    "        (\"removeIf\",RemoveIf(lambda d: d == 3.,\"rate\")),\n",
    "        (\"colSel\",ColumnSelector(\"rate\")),\n",
    "        ('ToLabelY', ToLabelYCls(fnc_basic,True))\n",
    "        ])\n",
    "    absice=list(range(debut,fin,pas))\n",
    "    ordonne={i:[] for i in range(6)}\n",
    "    #print(ordonne)\n",
    "    vvv=[]\n",
    "    plt.figure()\n",
    "    plt.title(\"Comparaison NB(nGRams et Voting(Soft|Hard)+stacking)\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    p=getPipelinesX(XpipeParams)\n",
    "    for i in range(debut,fin,pas):\n",
    "        reviews2=reviews[:i]\n",
    "        #print(i)\n",
    "        labels=p2.fit_transform(reviews2)\n",
    "        X_train, X_test, y_train, y_test  = train_test_split(p[\"UNI\"][-1].fit_transform(reviews2),labels)\n",
    "        from sklearn.ensemble import VotingClassifier\n",
    "        xx=[]\n",
    "        for k,v in p.iteritems():\n",
    "            xx+=[(k,v[0])]\n",
    "        #print(i)\n",
    "        sclf = StackingClassifier(classifiers=[i[1] for i in xx],\n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=LogisticRegression())\n",
    "        sclf.fit(X_train,y_train)\n",
    "        vv=VotingClassifier(estimators=xx,voting=voting)\n",
    "        vv.fit(X_train,y_train)\n",
    "        vv2=VotingClassifier(estimators=xx,voting=\"hard\")\n",
    "        vv2.fit(X_train,y_train)\n",
    "        ordonne[0].append(accuracy_score(y_test,vv.predict(X_test)))\n",
    "        ordonne[1].append(accuracy_score(y_test,vv2.predict(X_test)))\n",
    "        ordonne[2].append(accuracy_score(y_test,sclf.predict(X_test)))\n",
    "\n",
    "        for i in range(len(vv.estimators_)):\n",
    "            #print\"ii:\"+str(i)\n",
    "            #print(\"n: \"+str(i+1))\n",
    "            ordonne[i+3].append(accuracy_score(toHotCls(fnc_basic).transform(y_test),vv.estimators_[i].predict(X_test)))\n",
    "        vvv.append(vv)\n",
    "    #print(ordonne)\n",
    "    for z,(pd,i) in enumerate(ordonne.iteritems()):\n",
    "        #print(absice)\n",
    "        #print(i)\n",
    "        line1,=plot(absice,i,label=vvv[0].estimators[z-3][0] if z>2 else (\"Stacking\" if z>1 else (\"VotingHard\" if z>0 else \"VotingSoft\")))\n",
    "    #plt.legend(handler_map={line1: HandlerLine2D(numpoints=4)})\n",
    "    plt.legend(bbox_to_anchor=(1, 0.35), loc=0, borderaxespad=0.)\n",
    "    show()\n",
    "    return vvv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-697-b668af64bc21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-693-62d042a50e59>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(debut, fin, pas, voting)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mreviews2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"UNI\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \"\"\"\n\u001b[1;32m    300\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                               \u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-d50086246d2a>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lucasiscovici/Library/Python/2.7/lib/python/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lucasiscovici/Library/Python/2.7/lib/python/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lucasiscovici/Library/Python/2.7/lib/python/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lucasiscovici/Library/Python/2.7/lib/python/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/lucasiscovici/Library/Python/2.7/lib/python/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rate'"
     ]
    }
   ],
   "source": [
    "ab=test(0,100000,20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[VotingClassifier(estimators=[('TRI', Pipeline(steps=[('colSel', <__main__.ColumnSelector object at 0x122b87950>), ('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=...zer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))],\n",
       "          n_jobs=1, voting='soft', weights=None),\n",
       " VotingClassifier(estimators=[('TRI', Pipeline(steps=[('colSel', <__main__.ColumnSelector object at 0x122b87950>), ('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=...zer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))],\n",
       "          n_jobs=1, voting='soft', weights=None),\n",
       " VotingClassifier(estimators=[('TRI', Pipeline(steps=[('colSel', <__main__.ColumnSelector object at 0x122b87950>), ('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=...zer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))],\n",
       "          n_jobs=1, voting='soft', weights=None),\n",
       " VotingClassifier(estimators=[('TRI', Pipeline(steps=[('colSel', <__main__.ColumnSelector object at 0x122b87950>), ('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=...zer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))],\n",
       "          n_jobs=1, voting='soft', weights=None),\n",
       " VotingClassifier(estimators=[('TRI', Pipeline(steps=[('colSel', <__main__.ColumnSelector object at 0x122b87950>), ('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=...zer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))],\n",
       "          n_jobs=1, voting='soft', weights=None),\n",
       " VotingClassifier(estimators=[('TRI', Pipeline(steps=[('colSel', <__main__.ColumnSelector object at 0x122b87950>), ('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=...zer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))],\n",
       "          n_jobs=1, voting='soft', weights=None),\n",
       " VotingClassifier(estimators=[('TRI', Pipeline(steps=[('colSel', <__main__.ColumnSelector object at 0x122b87950>), ('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=...zer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))],\n",
       "          n_jobs=1, voting='soft', weights=None),\n",
       " VotingClassifier(estimators=[('TRI', Pipeline(steps=[('colSel', <__main__.ColumnSelector object at 0x122b87950>), ('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=...zer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))],\n",
       "          n_jobs=1, voting='soft', weights=None),\n",
       " VotingClassifier(estimators=[('TRI', Pipeline(steps=[('colSel', <__main__.ColumnSelector object at 0x122b87950>), ('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, max_df=1.0, max_features=...zer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]))],\n",
       "          n_jobs=1, voting='soft', weights=None)]"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "xx=[]\n",
    "for k,v in p.iteritems():\n",
    "    xx+=[v[0]]\n",
    "sclf = StackingClassifier(classifiers=xx,\n",
    "                          use_probas=True,\n",
    "                          average_probas=False,\n",
    "                          meta_classifier=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "          classifiers=[Pipeline(steps=[('colSel', <__main__.ColumnSelector object at 0x11ce348d0>), ('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, m...izer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])],\n",
       "          meta_classifier=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          store_train_meta_features=False, use_clones=True,\n",
       "          use_features_in_secondary=False, use_probas=True, verbose=0)"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85046728971962615"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sclf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#BUILD Var In Key of testVar with as value the classifier\n",
    "for k,v in testVar.iteritems():\n",
    "    cal=get_classifier(reviews2Tested,v,debug,Sklearn,SklearnParamNB,fnc=fnc)\n",
    "    val=[DecoClassif(cal[i][0],v,name=str(k)+\"_\"+fnc_basic.keys()[i]) for i in range(len(cal))] # FOR USE SKLEARN WE BUILD AN DECORATOR ( WITH PREDICT AND PREDICT_PROBA)\n",
    "    createVarPython(k,[val,cal[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs, re, time\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "\n",
    "# Vectorizing data.\n",
    "#train = []\n",
    "word_vectorizer = _3gram[0].decore._vectorizer\n",
    "#trainset = word_vectorizer.fit_transform(codecs.open(trainfile,'r','utf8'))\n",
    "#tags = ['bs','pt','bs','pt']\n",
    "\n",
    "# Training NB\n",
    "mnb = _3gram[0].decore._clf\n",
    "#mnb.fit(trainset, tags)\n",
    "\n",
    "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=100):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "\n",
    "    for coef, feat in topn_class1:\n",
    "        print class_labels[0], coef, feat\n",
    "\n",
    "    print\n",
    "\n",
    "    for coef, feat in reversed(topn_class2):\n",
    "        print class_labels[1], coef, feat\n",
    "\n",
    "\n",
    "most_informative_feature_for_binary_classification(word_vectorizer, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#To Test\n",
    "begin=100\n",
    "end=1000\n",
    "step=100\n",
    "for i in range(begin,end,step):\n",
    "    print(\"i: \"+str(i))\n",
    "    for j,v in testVar.iteritems():\n",
    "        print(j)\n",
    "        print(\"\\t\"+str(vars()[j][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#WE CREATE AN VOTING CLASSIFIER THAT NOT NEED TO FIT DATA | ONLY PREDICT or PREDICT_DATA\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "Estimators=[(\"n\"+str(i+1),vars()[j][0]) for i,j in enumerate(testVar)]\n",
    "eclf1 = VotingClassifier2(estimators=\n",
    "                          Estimators, \n",
    "                          voting='soft',y=fnc.keys()\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ACCURACY\n",
    " \n",
    "def accuracy_scoreWithPredict(X,Y,classif,Hot=True):\n",
    "    print(accuracy_score(GetTestY(X),classif.predict(Y,Hot=Hot)))\n",
    "\n",
    "def accuracy_scoreWithPredictProba(X,Y,classif):\n",
    "    print(accuracy_score(GetTestY(X),classif.predict(Y)))\n",
    "    \n",
    "#accuracy_score(GetTestY(reviews2[500:900][\"rate\"]),\n",
    "#               toLabel([np.argmax(i) for i in eclf1.predict_proba(reviews2[500:900][\"comment\"])\n",
    " #              ],Uni.decore)\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_scoreWithPredict(reviews2[5000:6000][\"rate\"],reviews2[5000:6000][\"comment\"],_3gram[0],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time accuracy_scoreWithPredict(reviews2[50000:100000][\"rate\"],reviews2[50000:100000][\"comment\"],_2gram[0],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To Test\n",
    "begin=100\n",
    "end=1000\n",
    "step=100\n",
    "for i in range(begin,end,step):\n",
    "    print(\"i: \"+str(i))\n",
    "    for j,v in testVar.iteritems():\n",
    "        print(j)\n",
    "        print(\"\\t\"+str(vars()[j][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "      % (iris.data.shape[0],(iris.target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, prob))\n",
    "print(metrics.confusion_matrix(iris.target, y_pred))\n",
    "print(metrics.accuracy_score(iris.target, y_pred))\n",
    "print(metrics.adjusted_mutual_info_score(iris.target, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.accuracy_score(log_model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.cluster.completeness_score(iris.target, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.cluster.v_measure_score(iris.target, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LabelEncoder\n",
    "class VotingClassifier2( ClassifierMixin, TransformerMixin):\n",
    "\n",
    "\n",
    "    def __init__(self, estimators, voting='hard', weights=None, n_jobs=1,\n",
    "                 flatten_transform=None,y=[]):\n",
    "        self.estimators = estimators\n",
    "        self.estimators_ = [ i[1] for i in estimators]\n",
    "        self.le_ = LabelEncoder().fit(y)\n",
    "        self.voting = voting\n",
    "        self.weights = weights\n",
    "        self.n_jobs = n_jobs\n",
    "        self.flatten_transform = flatten_transform\n",
    "\n",
    "    @property\n",
    "    def named_estimators(self):\n",
    "        return dict(self.estimators)\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def _weights_not_none(self):\n",
    "        \"\"\"Get the weights of not `None` estimators\"\"\"\n",
    "        if self.weights is None:\n",
    "            return None\n",
    "        return [w for est, w in zip(self.estimators,\n",
    "                                    self.weights) if est[1] is not None]\n",
    "\n",
    "    def predict(self, X,Hot=True):\n",
    "        \"\"\" Predict class labels for X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        ----------\n",
    "        maj : array-like, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "\n",
    "        #check_is_fitted(self, 'estimators_')\n",
    "        if self.voting == 'soft':\n",
    "            maj = np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "        else:  # 'hard' voting\n",
    "            predictions = self._predict(X,Hot=Hot)\n",
    "            print(predictions)\n",
    "            maj = np.apply_along_axis(\n",
    "                lambda x: np.argmax(\n",
    "                    np.bincount(x, weights=self._weights_not_none)),\n",
    "                axis=1, arr=predictions)\n",
    "\n",
    "        maj = self.le_.inverse_transform(maj)\n",
    "\n",
    "        return maj\n",
    "\n",
    "    def _collect_probas(self, X):\n",
    "        \"\"\"Collect results from clf.predict calls. \"\"\"\n",
    "        return np.asarray([clf.predict_proba(X) for clf in self.estimators_])\n",
    "\n",
    "    def _predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities for X in 'soft' voting \"\"\"\n",
    "        if self.voting == 'hard':\n",
    "            raise AttributeError(\"predict_proba is not available when\"\n",
    "                                 \" voting=%r\" % self.voting)\n",
    "        #check_is_fitted(self, 'estimators_')\n",
    "        avg = np.average(self._collect_probas(X), axis=0,\n",
    "                         weights=self._weights_not_none)\n",
    "        return avg\n",
    "\n",
    "    @property\n",
    "    def predict_proba(self):\n",
    "        \"\"\"Compute probabilities of possible outcomes for samples in X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        ----------\n",
    "        avg : array-like, shape = [n_samples, n_classes]\n",
    "            Weighted average probability for each class per sample.\n",
    "        \"\"\"\n",
    "        return self._predict_proba\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Return class labels or probabilities for X for each estimator.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        If `voting='soft'` and `flatten_transform=True`:\n",
    "          array-like = (n_classifiers, n_samples * n_classes)\n",
    "          otherwise array-like = (n_classifiers, n_samples, n_classes)\n",
    "            Class probabilities calculated by each classifier.\n",
    "        If `voting='hard'`:\n",
    "          array-like = [n_samples, n_classifiers]\n",
    "            Class labels predicted by each classifier.\n",
    "        \"\"\"\n",
    "        #check_is_fitted(self, 'estimators_')\n",
    "\n",
    "        if self.voting == 'soft':\n",
    "            probas = self._collect_probas(X)\n",
    "            if self.flatten_transform is None:\n",
    "                warnings.warn(\"'flatten_transform' default value will be \"\n",
    "                              \"changed to True in 0.21.\"\n",
    "                              \"To silence this warning you may\"\n",
    "                              \" explicitly set flatten_transform=False.\",\n",
    "                              DeprecationWarning)\n",
    "                return probas\n",
    "            elif not self.flatten_transform:\n",
    "                return probas\n",
    "            else:\n",
    "                return np.hstack(probas)\n",
    "\n",
    "        else:\n",
    "            return self._predict(X)\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\" Setting the parameters for the voting classifier\n",
    "        Valid parameter keys can be listed with get_params().\n",
    "        Parameters\n",
    "        ----------\n",
    "        params: keyword arguments\n",
    "            Specific parameters using e.g. set_params(parameter_name=new_value)\n",
    "            In addition, to setting the parameters of the ``VotingClassifier``,\n",
    "            the individual classifiers of the ``VotingClassifier`` can also be\n",
    "            set or replaced by setting them to None.\n",
    "        Examples\n",
    "        --------\n",
    "        # In this example, the RandomForestClassifier is removed\n",
    "        clf1 = LogisticRegression()\n",
    "        clf2 = RandomForestClassifier()\n",
    "        eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)])\n",
    "        eclf.set_params(rf=None)\n",
    "        \"\"\"\n",
    "        super(VotingClassifier, self)._set_params('estimators', **params)\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Get the parameters of the VotingClassifier\n",
    "        Parameters\n",
    "        ----------\n",
    "        deep: bool\n",
    "            Setting it to True gets the various classifiers and the parameters\n",
    "            of the classifiers as well\n",
    "        \"\"\"\n",
    "        return super(VotingClassifier,\n",
    "                     self)._get_params('estimators', deep=deep)\n",
    "\n",
    "    def _predict(self, X,Hot=False):\n",
    "        \"\"\"Collect results from clf.predict calls. \"\"\"\n",
    "        #print([clf.predict(X) for clf in self.estimators_])\n",
    "        return np.asarray([ toHotCls(fnc_basic).transform(clf.predict(X)) if Hot else clf.predict(X)  for clf in self.estimators_]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DecoClassifX( ClassifierMixin, TransformerMixin,BaseEstimator):\n",
    "\n",
    "    \n",
    "    def __init__(self,decore=None,fctFit=None, fctPredict=None,name=\"test\"):\n",
    "        self.decore = decore\n",
    "        self.fn = fctPredict\n",
    "        self.fnFit=fctFit\n",
    "        print(self.fnFit)\n",
    "        self.n=fctFit\n",
    "        print(fctFit)\n",
    "        self.name=name\n",
    "    def setUP(self,decore,fctFit, fctPredict,name=\"test\"):\n",
    "        self.decore = decore\n",
    "        self.fn = fctPredict\n",
    "        self.fnFit=fctFit\n",
    "        print(self.fnFit)\n",
    "        self.n=fctFit\n",
    "        print(fctFit)\n",
    "        self.name=name\n",
    "        return self\n",
    "       \n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Get the parameters of the VotingClassifier\n",
    "        Parameters\n",
    "        ----------\n",
    "        deep: bool\n",
    "            Setting it to True gets the various classifiers and the parameters\n",
    "            of the classifiers as well\n",
    "        \"\"\"\n",
    "        from copy import deepcopy\n",
    "        au= super(DecoClassifX,\n",
    "                     self).get_params(deep=deep)\n",
    "        return deepcopy(self)\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        print(self.fnFit)\n",
    "        print(self.n)\n",
    "        return self.decore.fit(self.fnFit(X),y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict class labels for X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        ----------\n",
    "        maj : array-like, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(self.fn(X))\n",
    "        k=self.decore.predict(self.fnFit(X))\n",
    "        return  k\n",
    "\n",
    "    def _collect_probas(self, X):\n",
    "        \"\"\"Collect results from clf.predict calls. \"\"\"\n",
    "        return self.decore._collect_probas(X)\n",
    "\n",
    "    def _predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities for X in 'soft' voting \"\"\"\n",
    "        #check_is_fitted(self, 'estimators_')\n",
    "        XX=[]\n",
    "        for i,f in enumerate(X):\n",
    "            XX.append(self.fn(f))\n",
    "        return self.decore.predict_proba(X)\n",
    "\n",
    "    @property\n",
    "    def predict_proba(self):\n",
    "        \"\"\"Compute probabilities of possible outcomes for samples in X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        ----------\n",
    "        avg : array-like, shape = [n_samples, n_classes]\n",
    "            Weighted average probability for each class per sample.\n",
    "        \"\"\"\n",
    "        return self._predict_proba\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Return class labels or probabilities for X for each estimator.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        If `voting='soft'` and `flatten_transform=True`:\n",
    "          array-like = (n_classifiers, n_samples * n_classes)\n",
    "          otherwise array-like = (n_classifiers, n_samples, n_classes)\n",
    "            Class probabilities calculated by each classifier.\n",
    "        If `voting='hard'`:\n",
    "          array-like = [n_samples, n_classifiers]\n",
    "            Class labels predicted by each classifier.\n",
    "        \"\"\"\n",
    "        return self.decore.transform(X)\n",
    "\n",
    "    def _predict(self, X):\n",
    "        \"\"\"Collect results from clf.predict calls. \"\"\"\n",
    "        return self.decore._predict(X)\n",
    "    def __repr__(self):\n",
    "        return \"DecoClassifX: \"+self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DecoClassif( ClassifierMixin, TransformerMixin):\n",
    "\n",
    "\n",
    "    def __init__(self, decore, fctPredict,name=\"test\"):\n",
    "        self.decore = decore\n",
    "        self.fn = fctPredict\n",
    "        self.name=name\n",
    "       \n",
    "\n",
    "    @property\n",
    "    def named_estimators(self):\n",
    "        return self.decore.named_estimators\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def _weights_not_none(self):\n",
    "        \"\"\"Get the weights of not `None` estimators\"\"\"\n",
    "        return self.decore._weights_not_none\n",
    "\n",
    "    def predict(self, X,Hot=True):\n",
    "        \"\"\" Predict class labels for X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        ----------\n",
    "        maj : array-like, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        XX=[]\n",
    "        for i,f in enumerate(X):\n",
    "            XX.append(self.fn(f))\n",
    "        k=self.decore.classify_many(XX)\n",
    "        return  toHot(k,self.decore.labels()) if Hot else k\n",
    "\n",
    "    def _collect_probas(self, X):\n",
    "        \"\"\"Collect results from clf.predict calls. \"\"\"\n",
    "        return self.decore._collect_probas(X)\n",
    "\n",
    "    def _predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities for X in 'soft' voting \"\"\"\n",
    "        #check_is_fitted(self, 'estimators_')\n",
    "        XX=[]\n",
    "        for i,f in enumerate(X):\n",
    "            XX.append(self.fn(f))\n",
    "        return giveMeProba(self.decore.labels(),self.decore.prob_classify_many(XX))\n",
    "\n",
    "    @property\n",
    "    def predict_proba(self):\n",
    "        \"\"\"Compute probabilities of possible outcomes for samples in X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        ----------\n",
    "        avg : array-like, shape = [n_samples, n_classes]\n",
    "            Weighted average probability for each class per sample.\n",
    "        \"\"\"\n",
    "        return self._predict_proba\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Return class labels or probabilities for X for each estimator.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        If `voting='soft'` and `flatten_transform=True`:\n",
    "          array-like = (n_classifiers, n_samples * n_classes)\n",
    "          otherwise array-like = (n_classifiers, n_samples, n_classes)\n",
    "            Class probabilities calculated by each classifier.\n",
    "        If `voting='hard'`:\n",
    "          array-like = [n_samples, n_classifiers]\n",
    "            Class labels predicted by each classifier.\n",
    "        \"\"\"\n",
    "        return self.decore.transform(X)\n",
    "\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        \"\"\" Setting the parameters for the voting classifier\n",
    "        Valid parameter keys can be listed with get_params().\n",
    "        Parameters\n",
    "        ----------\n",
    "        params: keyword arguments\n",
    "            Specific parameters using e.g. set_params(parameter_name=new_value)\n",
    "            In addition, to setting the parameters of the ``VotingClassifier``,\n",
    "            the individual classifiers of the ``VotingClassifier`` can also be\n",
    "            set or replaced by setting them to None.\n",
    "        Examples\n",
    "        --------\n",
    "        # In this example, the RandomForestClassifier is removed\n",
    "        clf1 = LogisticRegression()\n",
    "        clf2 = RandomForestClassifier()\n",
    "        eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2)]\n",
    "        eclf.set_params(rf=None)\n",
    "        \"\"\"\n",
    "        super(VotingClassifier, self)._set_params('estimators', **params)\n",
    "        return self\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\" Get the parameters of the VotingClassifier\n",
    "        Parameters\n",
    "        ----------\n",
    "        deep: bool\n",
    "            Setting it to True gets the various classifiers and the parameters\n",
    "            of the classifiers as well\n",
    "        \"\"\"\n",
    "        return super(VotingClassifier,\n",
    "                     self)._get_params('estimators', deep=deep)\n",
    "\n",
    "    def _predict(self, X):\n",
    "        \"\"\"Collect results from clf.predict calls. \"\"\"\n",
    "        return self._predict(X)\n",
    "    def __repr__(self):\n",
    "        return \"DecoClassif: \"+self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def giveMeProba(Bi,arr):\n",
    "    m=Bi\n",
    "    k=[]\n",
    "    for i in arr:\n",
    "        o=[]\n",
    "        for j in m:\n",
    "            o.append(i.prob(j))\n",
    "        k.append(o)\n",
    "    return k\n",
    "def toHot(arr,d):\n",
    "    m=d\n",
    "    k={\"FALSE\":-1}\n",
    "    kk=[]\n",
    "    for i,j in enumerate(m):\n",
    "        k[j]=i\n",
    "    for i in arr:\n",
    "        kk.append(k[i])\n",
    "    return np.array(kk,dtype=np.int)\n",
    "def toLabel(arr,d):\n",
    "    m=d\n",
    "    k={}\n",
    "    kk=[]\n",
    "    for i,j in enumerate(m):\n",
    "        k[i]=j\n",
    "    for i in arr:\n",
    "        kk.append(k[i])\n",
    "    return np.array(kk,dtype=np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                                 n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(v.estimators_[0],\"Voting\",X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
